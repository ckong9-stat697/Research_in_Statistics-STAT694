{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Project Data Cleaning\n",
    "### This notebook described how I clean the data extracted from Twitter\n",
    "#### This notebook is written in R."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(dplyr)\n",
    "#Understand the Data Structure\n",
    "data <- data[c(2:5)]\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Location Cleaning Function:\n",
    "location_cleaning_function <- function(df1){\n",
    "  count <- 1\n",
    "  for (i in df1$location){\n",
    "    if (grepl(\"San Francisco\", i, ignore.case=TRUE) == TRUE)\n",
    "    {\n",
    "      location_text <- \"San Francisco\"\n",
    "    }\n",
    "    else if (grepl(\"New York\", i, ignore.case=TRUE) == TRUE)\n",
    "    {\n",
    "      location_text <- \"New York\"\n",
    "    }\n",
    "    else if (grepl(\"Los Angeles\", i, ignore.case=TRUE) == TRUE)\n",
    "    {\n",
    "      location_text <- \"Los Angeles\"\n",
    "    }\n",
    "    else if (grepl(\"Miami\", i, ignore.case=TRUE) == TRUE)\n",
    "    {\n",
    "      location_text <- \"Miami\"\n",
    "    }\n",
    "    else if (grepl(\"Chicago\", i, ignore.case=TRUE) == TRUE)\n",
    "    {\n",
    "      location_text <- \"Chicago\"\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "      location_text <- i\n",
    "    }\n",
    "    df1$location[count] <- location_text\n",
    "    count = count + 1\n",
    "  }\n",
    "  return(df1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 <- location_cleaning_function(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Date Type\n",
    "data_2 <- data_1 %>%\n",
    "  mutate(tweetcreatedts = as.Date(tweetcreatedts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove Special Characters:\n",
    "main_text_clean <- function(df2){\n",
    "  count <- 1\n",
    "  for (text in df2$text) {\n",
    "    # Set the text to lowercase\n",
    "    text <- tolower(text)\n",
    "    # Remove mentions, urls, emojis, numbers, punctuations, etc.\n",
    "    text <- gsub(\"@\\\\w+\", \"\", text)\n",
    "    text <- gsub(\"https?://.+\", \"\", text)\n",
    "    text <- gsub(\"\\\\d+\\\\w*\\\\d*\", \"\", text)\n",
    "    text <- gsub(\"#\\\\w+\", \"\", text)\n",
    "    text <- gsub(\"[^\\x01-\\x7F]\", \"\", text)\n",
    "    text <- gsub(\"[[:punct:]]\", \" \", text)\n",
    "    # Remove spaces and newlines\n",
    "    text <- gsub(\"\\n\", \" \", text)\n",
    "    text <- gsub(\"^\\\\s+\", \"\", text)\n",
    "    text <- gsub(\"\\\\s+$\", \"\", text)\n",
    "    text <- gsub(\"[ |\\t]+\", \" \", text)\n",
    "    df2$text[count] <- text\n",
    "    count <- count + 1\n",
    "  }\n",
    "  return(df2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3 <- main_text_clean(data_2)\n",
    "write.csv(data_3, \"data/tweet_cleaned_withstopwords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(qdap)\n",
    "## Remove Stop Words\n",
    "main_text_clean_2 <- function(df3){\n",
    "  count <- 1\n",
    "  for (text in df3$text){\n",
    "    text <- rm_stopwords(text, stopwords = Top200Words, separate=FALSE)\n",
    "    df3$text[count] <- text\n",
    "    count <- count + 1\n",
    "  }\n",
    "  return(df3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4 <- main_text_clean_2(data_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write to csv\n",
    "write.csv(data_4, \"data/tweet_cleaned.csv\")"
   ]
  }
 ]
}